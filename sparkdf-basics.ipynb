{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we dont need to do the folliwng \n",
    "from pyspark import SparkContext, SQLContext\n",
    "#sc = SparkContext()\n",
    "\n",
    "#we need to write to get sqlcontext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "source : https://www.analyticsvidhya.com/blog/2016/10/spark-dataframe-and-operations/\n",
    "### How to create a DataFrame \n",
    "\n",
    "A DataFrame in Apache Spark can be created in multiple ways:\n",
    "\n",
    "- [It can be created using different data formats. For example, loading the data from JSON, CSV.]\n",
    "- [Loading data from Existing RDD.]\n",
    "- [Programmatically specifying schema]\n",
    "\n",
    "https://www.analyticsvidhya.com/wp-content/uploads/2016/10/DataFrame-in-Spark.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "l = [('Hasankeyfi',25),('Istanpoli',22),('ferahkoy',20),('Telin',26)]\n",
    "rdd = sc.parallelize(l)\n",
    "people = rdd.map(lambda x: Row(name=x[0], age=int(x[1])))\n",
    "schemaPeople = sqlContext.createDataFrame(people)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'pyspark.sql.dataframe.DataFrame'>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(schemaPeople)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = spark.read.csv(\"..//data/blackfridaypractice/train.csv\",header = True,inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = spark.read.csv(\"..//data/blackfridaypractice/test.csv\",header = True,inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- User_ID: integer (nullable = true)\n",
      " |-- Product_ID: string (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      " |-- Occupation: integer (nullable = true)\n",
      " |-- City_Category: string (nullable = true)\n",
      " |-- Stay_In_Current_City_Years: string (nullable = true)\n",
      " |-- Marital_Status: integer (nullable = true)\n",
      " |-- Product_Category_1: integer (nullable = true)\n",
      " |-- Product_Category_2: integer (nullable = true)\n",
      " |-- Product_Category_3: integer (nullable = true)\n",
      " |-- Purchase: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(User_ID=1000001, Product_ID='P00069042', Gender='F', Age='0-17', Occupation=10, City_Category='A', Stay_In_Current_City_Years='2', Marital_Status=0, Product_Category_1=3, Product_Category_2=None, Product_Category_3=None, Purchase=8370), Row(User_ID=1000001, Product_ID='P00248942', Gender='F', Age='0-17', Occupation=10, City_Category='A', Stay_In_Current_City_Years='2', Marital_Status=0, Product_Category_1=1, Product_Category_2=6, Product_Category_3=14, Purchase=15200), Row(User_ID=1000001, Product_ID='P00087842', Gender='F', Age='0-17', Occupation=10, City_Category='A', Stay_In_Current_City_Years='2', Marital_Status=0, Product_Category_1=12, Product_Category_2=None, Product_Category_3=None, Purchase=1422), Row(User_ID=1000001, Product_ID='P00085442', Gender='F', Age='0-17', Occupation=10, City_Category='A', Stay_In_Current_City_Years='2', Marital_Status=0, Product_Category_1=12, Product_Category_2=14, Product_Category_3=None, Purchase=1057), Row(User_ID=1000002, Product_ID='P00285442', Gender='M', Age='55+', Occupation=16, City_Category='C', Stay_In_Current_City_Years='4+', Marital_Status=0, Product_Category_1=8, Product_Category_2=None, Product_Category_3=None, Purchase=7969)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
      "|User_ID|Product_ID|Gender| Age|Occupation|City_Category|Stay_In_Current_City_Years|Marital_Status|Product_Category_1|Product_Category_2|Product_Category_3|Purchase|\n",
      "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
      "|1000001| P00069042|     F|0-17|        10|            A|                         2|             0|                 3|              null|              null|    8370|\n",
      "|1000001| P00248942|     F|0-17|        10|            A|                         2|             0|                 1|                 6|                14|   15200|\n",
      "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.show(2,truncate= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(550068, 233599)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.count(),test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, ['User_ID', 'Product_ID', 'Gender', 'Age', 'Occupation', 'City_Category', 'Stay_In_Current_City_Years', 'Marital_Status', 'Product_Category_1', 'Product_Category_2', 'Product_Category_3', 'Purchase'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train.columns), train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, ['User_ID', 'Product_ID', 'Gender', 'Age', 'Occupation', 'City_Category', 'Stay_In_Current_City_Years', 'Marital_Status', 'Product_Category_1', 'Product_Category_2', 'Product_Category_3'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test.columns), test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, User_ID: string, Product_ID: string, Gender: string, Age: string, Occupation: string, City_Category: string, Stay_In_Current_City_Years: string, Marital_Status: string, Product_Category_1: string, Product_Category_2: string, Product_Category_3: string, Purchase: string]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+----------+------+------+-----------------+-------------+--------------------------+-------------------+------------------+------------------+------------------+-----------------+\n",
      "|summary|           User_ID|Product_ID|Gender|   Age|       Occupation|City_Category|Stay_In_Current_City_Years|     Marital_Status|Product_Category_1|Product_Category_2|Product_Category_3|         Purchase|\n",
      "+-------+------------------+----------+------+------+-----------------+-------------+--------------------------+-------------------+------------------+------------------+------------------+-----------------+\n",
      "|  count|            550068|    550068|550068|550068|           550068|       550068|                    550068|             550068|            550068|            376430|            166821|           550068|\n",
      "|   mean|1003028.8424013031|      null|  null|  null|8.076706879876669|         null|         1.468494139793958|0.40965298835780306| 5.404270017525106| 9.842329251122386|12.668243206790512|9263.968712959126|\n",
      "| stddev|1727.5915855313278|      null|  null|  null|6.522660487341822|         null|        0.9890866807573164|0.49177012631733186| 3.936211369201384| 5.086589648693496|4.1253376315752845|5023.065393820554|\n",
      "|    min|           1000001| P00000142|     F|  0-17|                0|            A|                         0|                  0|                 1|                 2|                 3|               12|\n",
      "|    max|           1006040|  P0099942|     M|   55+|               20|            C|                        4+|                  1|                20|                18|                18|            23961|\n",
      "+-------+------------------+----------+------+------+-----------------+-------------+--------------------------+-------------------+------------------+------------------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary statistics\n",
    "As we can see that, describe operation is working for String type\n",
    "column but the output for mean, stddev are \n",
    "null and min & max values are calculated based on ASCII value of categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+\n",
      "|summary|Product_ID|\n",
      "+-------+----------+\n",
      "|  count|    550068|\n",
      "|   mean|      null|\n",
      "| stddev|      null|\n",
      "|    min| P00000142|\n",
      "|    max|  P0099942|\n",
      "+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.describe('Product_ID').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<b'Product_ID DESC NULLS LAST'>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Product_ID.desc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to select column(s) from the DataFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+\n",
      "|User_ID| Age|\n",
      "+-------+----+\n",
      "|1000001|0-17|\n",
      "|1000001|0-17|\n",
      "|1000001|0-17|\n",
      "|1000001|0-17|\n",
      "|1000002| 55+|\n",
      "+-------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.select('User_ID','Age').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to find the number of distinct product in train and test files?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3631, 3491)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.select('Product_ID').distinct().count(), test.select('Product_ID').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#diff_cat_in_train_test=test.select('Product_ID').subtract(train.select('Product_ID'))\n",
    "#diff_cat_in_train_test.distinct().count()# For distict count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What if I want to calculate pair wise frequency of categorical columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+------+\n",
      "|Age_Gender|    F|     M|\n",
      "+----------+-----+------+\n",
      "|      0-17| 5083| 10019|\n",
      "|     46-50|13199| 32502|\n",
      "|     18-25|24628| 75032|\n",
      "|     36-45|27170| 82843|\n",
      "|       55+| 5083| 16421|\n",
      "|     51-55| 9894| 28607|\n",
      "|     26-35|50752|168835|\n",
      "+----------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.crosstab('Age', 'Gender').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------+-----+\n",
      "|Age_Marital_Status|     0|    1|\n",
      "+------------------+------+-----+\n",
      "|              0-17| 15102|    0|\n",
      "|             46-50| 12690|33011|\n",
      "|             18-25| 78544|21116|\n",
      "|             36-45| 66377|43636|\n",
      "|               55+|  7883|13621|\n",
      "|             51-55| 10839|27662|\n",
      "|             26-35|133296|86291|\n",
      "+------------------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.crosstab('Age', 'Marital_Status').show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What If I want to get the DataFrame which won’t have duplicate rows of given DataFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|  Age|Gender|\n",
      "+-----+------+\n",
      "|51-55|     F|\n",
      "|18-25|     M|\n",
      "| 0-17|     F|\n",
      "|46-50|     M|\n",
      "|18-25|     F|\n",
      "|  55+|     M|\n",
      "|  55+|     F|\n",
      "|36-45|     M|\n",
      "|26-35|     F|\n",
      "| 0-17|     M|\n",
      "|36-45|     F|\n",
      "|51-55|     M|\n",
      "|26-35|     M|\n",
      "|46-50|     F|\n",
      "+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.select('Age','Gender').dropDuplicates().show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What if I want to drop the all rows with null value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "550068"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166821"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dropna().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What if I want to fill the null values in DataFrame with constant number?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
      "|User_ID|Product_ID|Gender| Age|Occupation|City_Category|Stay_In_Current_City_Years|Marital_Status|Product_Category_1|Product_Category_2|Product_Category_3|Purchase|\n",
      "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
      "|1000001| P00069042|     F|0-17|        10|            A|                         2|             0|                 3|                -1|                -1|    8370|\n",
      "|1000001| P00248942|     F|0-17|        10|            A|                         2|             0|                 1|                 6|                14|   15200|\n",
      "|1000001| P00087842|     F|0-17|        10|            A|                         2|             0|                12|                -1|                -1|    1422|\n",
      "|1000001| P00085442|     F|0-17|        10|            A|                         2|             0|                12|                14|                -1|    1057|\n",
      "|1000002| P00285442|     M| 55+|        16|            C|                        4+|             0|                 8|                -1|                -1|    7969|\n",
      "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.fillna(-1).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  If I want to filter the rows in train which has Purchase more than 15000?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+------+-----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
      "|User_ID|Product_ID|Gender|  Age|Occupation|City_Category|Stay_In_Current_City_Years|Marital_Status|Product_Category_1|Product_Category_2|Product_Category_3|Purchase|\n",
      "+-------+----------+------+-----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
      "|1000001| P00248942|     F| 0-17|        10|            A|                         2|             0|                 1|                 6|                14|   15200|\n",
      "|1000003| P00193542|     M|26-35|        15|            A|                         3|             0|                 1|                 2|              null|   15227|\n",
      "|1000004| P00184942|     M|46-50|         7|            B|                         2|             1|                 1|                 8|                17|   19215|\n",
      "+-------+----------+------+-----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.filter(train.Purchase > 15000).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110523"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.filter(train.Purchase > 15000).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to find the mean of each age group in train?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------+\n",
      "|  Age|    avg(Purchase)|\n",
      "+-----+-----------------+\n",
      "|18-25|9169.663606261289|\n",
      "|26-35|9252.690632869888|\n",
      "| 0-17|8933.464640444974|\n",
      "|46-50|9208.625697468327|\n",
      "|51-55|9534.808030960236|\n",
      "|36-45|9331.350694917874|\n",
      "|  55+|9336.280459449405|\n",
      "+-----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.groupby('Age').agg({'Purchase':'mean'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|  Age| count|\n",
      "+-----+------+\n",
      "|18-25| 99660|\n",
      "|26-35|219587|\n",
      "| 0-17| 15102|\n",
      "|46-50| 45701|\n",
      "|51-55| 38501|\n",
      "|36-45|110013|\n",
      "|  55+| 21504|\n",
      "+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.groupby('Age').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|  Age| count|\n",
      "+-----+------+\n",
      "| 0-17| 15102|\n",
      "|  55+| 21504|\n",
      "|51-55| 38501|\n",
      "|46-50| 45701|\n",
      "|18-25| 99660|\n",
      "|36-45|110013|\n",
      "|26-35|219587|\n",
      "+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.groupby('Age').count().orderBy('count').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|  Age| count|\n",
      "+-----+------+\n",
      "| 0-17| 15102|\n",
      "|18-25| 99660|\n",
      "|26-35|219587|\n",
      "|36-45|110013|\n",
      "|46-50| 45701|\n",
      "|51-55| 38501|\n",
      "|  55+| 21504|\n",
      "+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.groupby('Age').count().orderBy('Age').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to create a sample DataFrame from the base DataFrame?\n",
    "We can use sample operation to take sample of a DataFrame. The sample method on DataFrame will return a DataFrame containing the sample of base DataFrame. The sample method will take 3 parameters.\n",
    "```\n",
    "    withReplacement = True or False to select a observation with or without replacement.\n",
    "    fraction = x, where x = .5 shows that we want to have 50% data in sample DataFrame.\n",
    "    seed for reproduce the result\n",
    "```\n",
    "Let’s create the two DataFrame t1 and t2 from train, both will have 20% sample of train and count the number of rows in each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t1 = train.sample(False,0.2,42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t2 = train.sample(False,0.2,83)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109924, 109826)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.count(),t2.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to apply map operation on DataFrame columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'pyspark.sql.dataframe.DataFrame'>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train.select('User_ID'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.select('User_ID').foreach(lambda x:(x,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to sort the DataFrame based on column(s)?\n",
    "We can use orderBy operation on DataFrame to get sorted output based on some column. The orderBy operation take two arguments.\n",
    "\n",
    "    List of columns.\n",
    "    ascending = True or False for getting the results in ascending or descending order(list in case of more than two columns )\n",
    "\n",
    "Let’s sort the train DataFrame based on ‘Purchase’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<b'Purchase DESC NULLS LAST'>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Purchase.desc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+------+-----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
      "|User_ID|Product_ID|Gender|  Age|Occupation|City_Category|Stay_In_Current_City_Years|Marital_Status|Product_Category_1|Product_Category_2|Product_Category_3|Purchase|\n",
      "+-------+----------+------+-----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
      "|1002272| P00052842|     M|26-35|         0|            C|                         1|             0|                10|                15|              null|   23961|\n",
      "|1003160| P00052842|     M|26-35|        17|            C|                         3|             0|                10|                15|              null|   23961|\n",
      "|1001474| P00052842|     M|26-35|         4|            A|                         2|             1|                10|                15|              null|   23961|\n",
      "|1005848| P00119342|     M|51-55|        20|            A|                         0|             1|                10|                13|              null|   23960|\n",
      "|1005596| P00117642|     M|36-45|        12|            B|                         1|             0|                10|                16|              null|   23960|\n",
      "+-------+----------+------+-----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.orderBy(train.Purchase.desc()).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to add the new column in DataFrame?\n",
    "We can use withColumn operation to add new column (we can also replace) in base DataFrame and return a new DataFrame. The withColumn operation will take 2 parameters.\n",
    "\n",
    "    Column name which we want add /replace.\n",
    "    Expression on column.\n",
    "\n",
    "Let’s see how withColumn works. I am calculating new column name ‘Purchase_new’ in train which is calculated by dviding Purchase column by 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+\n",
      "|Purchase|Purchase_new|\n",
      "+--------+------------+\n",
      "|    8370|      4185.0|\n",
      "|   15200|      7600.0|\n",
      "|    1422|       711.0|\n",
      "|    1057|       528.5|\n",
      "|    7969|      3984.5|\n",
      "+--------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.withColumn('Purchase_new', train.Purchase /2.0).select('Purchase','Purchase_new').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to drop a column in DataFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['User_ID',\n",
       " 'Product_ID',\n",
       " 'Gender',\n",
       " 'Age',\n",
       " 'Occupation',\n",
       " 'City_Category',\n",
       " 'Stay_In_Current_City_Years',\n",
       " 'Marital_Status',\n",
       " 'Product_Category_1',\n",
       " 'Product_Category_2',\n",
       " 'Product_Category_3']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.drop('Comb').columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What if I want to remove some categories of Product_ID column in test that are not present in Product_ID column in train?\n",
    "Here, we can use a user defined function ( udf ) to remove the categories of a column which are in test but not in train. Let’s again calculate the categories in Product_ID column which are in test but not in train.\n",
    "\n",
    "We have got 46 different categories in test. For removing these categories from the test ‘Product_ID’ column. I am applying these steps.\n",
    "\n",
    "Create the distinct list of categories called ‘not_found_cat’ from the diff_cat_in_train_test using map operation.\n",
    "Register a udf(user define function).\n",
    "User defined function will take each element of test column and search this in not_found_cat list and it will put -1 if  it finds in this list otherwise it will do nothing.\n",
    "\n",
    "Let’s see how it works. First create ‘not_found_cat’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainprodist = train.select('Product_ID').distinct()\n",
    "testprodist = test.select('Product_ID').distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|Product_ID|\n",
      "+----------+\n",
      "| P00322642|\n",
      "| P00300142|\n",
      "| P00077642|\n",
      "| P00249942|\n",
      "| P00294942|\n",
      "+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "diff_cat_in_train_test=testprodist.subtract(trainprodist)\n",
    "diff_cat_in_train_test.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_found_cat = diff_cat_in_train_test.rdd.map(lambda x:x[0]).collect()\n",
    "#not_found_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now resister the udf, we need to import StringType from the pyspark.sql and udf from the pyspark.sql.functions. The udf function takes 2 parameters as arguments:\n",
    "\n",
    "    -Function (I am using lambda function)\n",
    "    -Return type (in my case StringType())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.functions import udf\n",
    "F1 = udf(lambda x: '-1' if x in not_found_cat else x, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = test.withColumn(\"NEW_Product_ID\",F1(test[\"Product_ID\"])).select('NEW_Product_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "diff_cat_in_train_test=k.select('NEW_Product_ID').subtract(train.select('Product_ID'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#diff_cat_in_train_test.distinct().count()# For distinct "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to Apply SQL Queries on DataFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.registerTempTable('train_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|Product_ID|\n",
      "+----------+\n",
      "| P00069042|\n",
      "| P00248942|\n",
      "| P00087842|\n",
      "| P00085442|\n",
      "| P00285442|\n",
      "+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql('select Product_ID from train_table').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+\n",
      "|  Age|max(Purchase)|\n",
      "+-----+-------------+\n",
      "|18-25|        23958|\n",
      "|26-35|        23961|\n",
      "| 0-17|        23955|\n",
      "|46-50|        23960|\n",
      "|51-55|        23960|\n",
      "|36-45|        23960|\n",
      "|  55+|        23960|\n",
      "+-----+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql('select Age, max(Purchase) from train_table group by Age').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How can I convert to Pandas ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf = test.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<class 'pandas.core.frame.DataFrame'>, <class 'pyspark.sql.dataframe.DataFrame'>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(testdf),type(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - PySpark",
   "language": "python",
   "name": "apache_toree_pyspark"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "pygments_lexer": "python",
   "version": "3.6.3\n"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
